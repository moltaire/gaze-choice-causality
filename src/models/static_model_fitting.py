#!/usr/bin/python
import argparse
from functools import partial
from os import makedirs
from os.path import exists, join

import numpy as np
import pandas as pd
from src.models import staticmodels as md
from src.utilities import str2bool


def run_model_fitting():

    # Define models to be fit
    models = [
        md.TwoStageWithin,
        md.TwoStageBetween,
        md.TwoStageMixtureNoScaling,
        md.ExpectedUtility,
        md.ExpectedUtilityBLast,
        md.ExpectedUtilityBLastBLonger,
        md.ExpectedUtilityDurWeighted,
        md.ProspectTheory,
        md.ProspectTheoryBLast,
        md.ProspectTheoryBLastBLonger,
        md.WeightedAdditive,
        md.WeightedAdditiveBLast,
        md.WeightedAdditiveBLastBLonger,
        md.WeightedAdditiveDN,
        md.WeightedAdditiveDNBLast,
        md.WeightedAdditiveDNBLastBLonger,
        md.OutcomeCutoff,
        md.OutcomeCutoffBLast,
        md.OutcomeCutoffBLastBLonger,
    ]

    # Load choice data
    choices = pd.read_csv(args.data_file, index_col=0)
    n_all = len(choices)
    # Remove trials with missing responses
    choices = choices[~pd.isnull(choices["choice"])]
    if args.verbose > 0:
        print(f"Removed {n_all - len(choices)} trials with missing responses.")

    # 1. (Parallel, if specified) maximum likelihood estimation and prediction of all models listed in `models`
    # ---------------------------------------------------------------------------------------------------------

    if args.split_by_presentation:
        choices["subject_id"] = (
            choices["subject_id"].astype(str) + "-" + choices["presentation"]
        )
    subjects = np.unique(choices["subject_id"])
    n_subjects = len(subjects)

    def input_generator(data, subjects, models, verbose=False):
        "Generates subject-wise inputs to fit_subject_model function."
        for model in models:
            if args.verbose > 0:
                _ = model(data=data)
                print(
                    "{}: Parameter estimation and choice prediction...".format(_.label)
                )
                del _
            for subject in subjects:
                # Subset subject data
                subject_data = data[data["subject_id"] == subject].copy()
                # Initialize model instance
                subject_model = model(data=subject_data)
                subject_model.subject = subject
                # Yield everything as a tuple to input into fit_subject_model function
                yield subject, subject_model

    # Fix some arguments of the fitting function, so that it only takes subject data as argument
    fit_predict = partial(
        fit_predict_subject_model,
        n_runs=args.n_runs,
        optmethod=args.optmethod,
        n_sims=args.n_sims,
        output_dir=args.output_dir,
        label=args.label,
        seed=args.seed,
        overwrite=args.overwrite,
        verbose=args.verbose,
    )

    # Run fitting in parallel if multiple cores specified
    if args.n_cores > 1:
        from multiprocessing import Pool

        pool = Pool(args.n_cores)
        # next line can use `map`, then outputs work fine, or `imap_unordered` which maps better, but messes with output concatenation.
        results = pool.map(
            fit_predict, input_generator(choices, subjects, models, args.verbose)
        )
        all_estimates = [result[0] for result in results]
        all_predictions = [result[1] for result in results]
    # otherwise sequential
    else:
        all_estimates = []
        all_predictions = []
        for s, (subject, subject_model) in enumerate(
            input_generator(choices, subjects, models, args.verbose)
        ):
            if args.verbose > 0:
                print("Subject {} ({}/{})".format(subject, s + 1, n_subjects))
            (estimates, predictions) = fit_predict((subject, subject_model))
            all_estimates.append(estimates)
            all_predictions.append(predictions)

    # Collect and save results
    all_estimates_output_path = join(
        args.output_dir, "estimates", "estimates{}.csv"
    ).format(args.label)
    all_estimates = pd.concat(all_estimates, sort=True)
    all_estimates.to_csv(all_estimates_output_path, index=False)
    all_predictions_output_path = join(
        args.output_dir, "predictions", "predictions{}.csv"
    ).format(args.label)
    all_predictions = pd.concat(all_predictions, sort=True)
    all_predictions.to_csv(all_predictions_output_path, index=False)


def fit_predict_subject_model(
    variable_input,
    n_runs=1,
    optmethod="minimize",
    n_sims=1,
    output_dir="",
    label="",
    seed=None,
    overwrite=False,
    verbose=False,
):
    """
    Fit single subject model and predict choices from it.
    variable_input is generated by input_generator() and contains
    the subject ID, the model instance with attached data.
    """
    # Unpack input
    subject, subject_model = variable_input
    model_label = subject_model.label.replace(" ", "-").lower()

    # Organize output folders
    estimates_output_folder = join(output_dir, "estimates", model_label)
    predictions_output_folder = join(output_dir, "predictions", model_label)
    if not exists(estimates_output_folder):
        makedirs(estimates_output_folder)
    if not exists(predictions_output_folder):
        makedirs(predictions_output_folder)

    # Create output filenames
    estimates_output_file = "estimates_{}_{}{}.csv".format(model_label, subject, label)
    estimates_output_path = join(estimates_output_folder, estimates_output_file)
    predictions_output_file = "predictions_{}_{}{}.csv".format(
        model_label, subject, label
    )
    predictions_output_path = join(predictions_output_folder, predictions_output_file)

    # Parameter estimation
    if not overwrite and exists(estimates_output_path):
        if verbose > 0:
            print(
                "Found existing estimates at '{}'. Skipping estimation...".format(
                    estimates_output_path
                )
            )
        estimates_df = pd.read_csv(estimates_output_path)
        estimates = [
            estimates_df[parameter].values[0]
            for parameter in subject_model.parameter_names
        ]
        estimates_df["bic"] = (
            2 * estimates_df["nll"]
            + np.log(subject_model.n_trials) * subject_model.n_parameters
        )
    else:
        estimates, nll = subject_model.fit(
            method=optmethod, n_runs=n_runs, seed=seed, verbose=verbose
        )
        bic = 2 * nll + np.log(subject_model.n_trials) * subject_model.n_parameters
        # Put fitting results into DataFrame row
        estimates_df = pd.DataFrame(
            dict(subject=subject, nll=nll, bic=bic, model=model_label), index=[subject]
        )

        # Recover parameters, too
        recovery_results = subject_model.recover(
            parameters_gen=estimates,
            method=optmethod,
            n_runs=n_runs,
            seed=seed,
            verbose=verbose,
        )

        # Put together data frame
        for parameter, estimate in zip(subject_model.parameter_names, estimates):
            estimates_df[parameter] = estimate
            estimates_df[parameter + "_rec"] = recovery_results[
                parameter + "_rec"
            ].values[0]
        estimates_df["nll_rec"] = recovery_results["nll"].values[0]
        estimates_df.to_csv(estimates_output_path, index=False)

    # Prediction
    if not overwrite and exists(predictions_output_path):
        if verbose:
            print(
                "Found existing predictions at '{}'. Skipping prediction...".format(
                    predictions_output_path
                )
            )
        predictions_df = pd.read_csv(predictions_output_path)
    else:
        predictions_df = []
        predicted_choiceprobs = subject_model.predict_choiceprobs(parameters=estimates)
        for rep in range(n_sims):
            predicted_choices = subject_model.simulate_choices(parameters=estimates)
            predictions_rep_df = subject_model.data.copy()
            predictions_rep_df["predicted_choice"] = predicted_choices
            for i, option in enumerate([0, 1]):
                predictions_rep_df[
                    f"predicted_choiceprob_{option}"
                ] = predicted_choiceprobs[:, i]
            predictions_rep_df["model"] = model_label
            predictions_rep_df["rep"] = rep
            predictions_df.append(predictions_rep_df)
        predictions_df = pd.concat(predictions_df)
        predictions_df.to_csv(predictions_output_path, index=False)
    return estimates_df, predictions_df


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--verbose", default=0, type=int, help="Set verbosity (0, 1, >1)."
    )
    parser.add_argument(
        "--data-file",
        type=str,
        default="data/processed/choices.csv",
        help="Relative path to preprocessed choice data file.",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="models/model_fitting",
        help="Where to save results.",
    )
    parser.add_argument(
        "--label",
        type=str,
        default="",
        help="Analysis label (appended to output filename).",
    )
    parser.add_argument(
        "--optmethod",
        type=str,
        default="differential_evolution",
        help="scipy optimizer. Use 'minimize' or 'differential_evolution'.",
    )
    parser.add_argument(
        "--overwrite",
        type=str2bool,
        nargs="?",
        const=True,
        default=False,
        help="Toggle overwriting of existing result files.",
    )
    parser.add_argument(
        "--n-cores",
        type=int,
        default=1,
        help="Number of cores for parallel processing.",
    )

    parser.add_argument(
        "--split-by-presentation",
        type=str2bool,
        nargs="?",
        const=True,
        default=False,
        help="Toggle separate fitting for by-attribute and by-alternative trials.",
    )

    parser.add_argument(
        "--n-runs", type=int, default=50, help="Number of optimization runs per model."
    )
    parser.add_argument(
        "--n-sims",
        type=int,
        default=1,
        help="Number of simulation repetitions per trial.",
    )
    parser.add_argument("--seed", type=int, default=2021, help="Random number seed.")

    args = parser.parse_args()

    np.random.seed(args.seed)

    run_model_fitting()
